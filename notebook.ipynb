{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, tune, and deploy a custom ML model using the Time Series Classification (LSTM-FCN) Algorithm from AWS Marketplace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Time Series Classification (LSTM-FCN) Algorithm from AWS Marketplace](https://aws.amazon.com/marketplace/pp/prodview-vzxmyw25oqtx6) performs time series classification with the Long Short-Term Memory Fully Convolutional Network (LSTM-FCN) model. It implements both training and inference from CSV data and supports both CPU and GPU instances. The training and inference Docker images were built by extending the PyTorch 2.0 Python 3.10 SageMaker containers. \n",
    "\n",
    "#### Model Overview  \n",
    "The LSTM-FCN model includes two blocks: a recurrent block and a convolutional block.\n",
    "The recurrent block consists of a single LSTM layer followed by a dropout layer.\n",
    "The convolutional block consists of three convolutional layers, each followed by batch normalization and ReLU activation, and of a global average pooling layer.\n",
    "The input time series are passed to both blocks. \n",
    "The convolutional block processes each time series as a single feature observed across multiple time steps, while the recurrent block processes each time series as multiple features observed at a single time step (referred to as dimension shuffling).\n",
    "The outputs of the two blocks are concatenated and passed to a final output layer with softmax activation. \n",
    "\n",
    "<img src=https://fg-research-assets.s3.eu-west-1.amazonaws.com/lstm-fcn-diagram.png style=\"width:80%;margin-top:30px;margin-bottom:20px\"/>\n",
    "\n",
    "*LSTM-FCN architecture (source: [doi: 10.1109/ACCESS.2017.2779939](https://doi.org/10.1109/ACCESS.2017.2779939))*\n",
    "\n",
    "#### Model Resources \n",
    "- **Paper:** [LSTM Fully Convolutional Networks for Time Series Classification](https://doi.org/10.1109/ACCESS.2017.2779939)\n",
    "- **Repository:** [LSTM-FCN Official GitHub Repository](https://github.com/titu1994/LSTM-FCN)\n",
    "\n",
    "This sample notebook shows you how to train a custom ML model using the [Time Series Classification (LSTM-FCN) Algorithm from AWS Marketplace](https://aws.amazon.com/marketplace/pp/prodview-vzxmyw25oqtx6).\n",
    "\n",
    "**Note: This is a reference notebook and it cannot run unless you make the changes suggested in the notebook.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-requisites\n",
    "1. This notebook contains elements which render correctly in Jupyter interface. Open this notebook from an Amazon SageMaker Notebook Instance or Amazon SageMaker Studio.\n",
    "1. Ensure that IAM role used has **AmazonSageMakerFullAccess**\n",
    "1. Some hands-on experience using [Amazon SageMaker](https://aws.amazon.com/sagemaker/).\n",
    "1. To use this algorithm successfully, ensure that:\n",
    "    1. Either your IAM role has these three permissions and you have authority to make AWS Marketplace subscriptions in the AWS account used: \n",
    "        1. **aws-marketplace:ViewSubscriptions**\n",
    "        1. **aws-marketplace:Unsubscribe**\n",
    "        1. **aws-marketplace:Subscribe**  \n",
    "    2. or your AWS account has a subscription to the [Time Series Classification (LSTM-FCN) Algorithm from AWS Marketplace](https://aws.amazon.com/marketplace/pp/prodview-vzxmyw25oqtx6)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "1. [Subscribe to the algorithm](#1.-Subscribe-to-the-algorithm)\n",
    "1. [Prepare dataset](#2.-Prepare-dataset)\n",
    "\t1. [Dataset format expected by the algorithm](#A.-Dataset-format-expected-by-the-algorithm)\n",
    "\t1. [Configure and visualize train and test dataset](#B.-Configure-and-visualize-train-and-test-dataset)\n",
    "\t1. [Upload datasets to Amazon S3](#C.-Upload-datasets-to-Amazon-S3)\n",
    "1. [Train a machine learning model](#3:-Train-a-machine-learning-model)\n",
    "\t1. [Set up environment](#3.1-Set-up-environment)\n",
    "\t1. [Train a model](#3.2-Train-a-model)\n",
    "1. [Deploy model and verify results](#4:-Deploy-model-and-verify-results)\n",
    "    1. [Deploy trained model](#A.-Deploy-trained-model)\n",
    "    1. [Create input payload](#B.-Create-input-payload)\n",
    "    1. [Perform real-time inference](#C.-Perform-real-time-inference)\n",
    "    1. [Visualize output](#D.-Visualize-output)\n",
    "    1. [Calculate relevant metrics](#E.-Calculate-relevant-metrics)\n",
    "    1. [Delete the endpoint](#F.-Delete-the-endpoint)\n",
    "1. [Tune your model! (optional)](#5:-Tune-your-model!-(optional))\n",
    "\t1. [Tuning Guidelines](#A.-Tuning-Guidelines)\n",
    "\t1. [Define Tuning configuration](#B.-Define-Tuning-configuration)\n",
    "\t1. [Run a model tuning job](#C.-Run-a-model-tuning-job)\n",
    "1. [Perform Batch inference](#6.-Perform-Batch-inference)\n",
    "1. [Clean-up](#7.-Clean-up)\n",
    "\t1. [Delete the model](#A.-Delete-the-model)\n",
    "\t1. [Unsubscribe to the listing (optional)](#B.-Unsubscribe-to-the-listing-(optional))\n",
    "\n",
    "\n",
    "## Usage instructions\n",
    "You can run this notebook one cell at a time (By using Shift+Enter for running a cell)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Subscribe to the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To subscribe to the algorithm:\n",
    "1. Open the algorithm listing page.\n",
    "1. On the AWS Marketplace listing, click on **Continue to subscribe** button.\n",
    "1. On the **Subscribe to this software** page, review and click on **\"Accept Offer\"** if you agree with EULA, pricing, and support terms. \n",
    "1. Once you click on the **Continue to configuration** button and then choose a **region**, you will see a **Product ARN**. This is the algorithm ARN that you need to specify while training a custom ML model. **Copy the ARN corresponding to your region and specify the same in the following cell.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "algo_arn = \"arn:aws:sagemaker:eu-west-1:661670223746:algorithm/lstm-fcn-algo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sagemaker-eu-west-1-661670223746'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Dataset format expected by the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training and validation datasets should be provided as CSV files. \n",
    "The datasets should contain the time series and their class labels.\n",
    "Each row of the CSV file represents a time series, while each column represents a time step.\n",
    "All time series should have the same length and should not contain missing values.\n",
    "\n",
    "The class labels should be stored in the first column, while the time series should be stored in the subsequent columns.\n",
    "The class labels should be integers from `0` to `N - 1`, where `N` is the number of classes.\n",
    "The CSV file should not contain any index column or column headers. \n",
    "\n",
    "You can find more information about dataset format in the **Usage Information** section of the algorithm listing page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Configure and visualize train and test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample data provided in the algorithm's GitHub repository (https://github.com/fg-research/lstm-fcn-sagemaker) consists of three classes of artificially generated time series. The length of each time series is 100 time steps. The training dataset contains 700 time series, while the validation and test datasets contain 150 time series. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Training dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_dataset = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/fg-research/lstm-fcn-sagemaker/master/data/training/train.csv\",\n",
    "    header=None,\n",
    "    index_col=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 101)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.653245</td>\n",
       "      <td>12.503635</td>\n",
       "      <td>0.364683</td>\n",
       "      <td>8.849870</td>\n",
       "      <td>15.112630</td>\n",
       "      <td>13.802204</td>\n",
       "      <td>10.928423</td>\n",
       "      <td>3.953502</td>\n",
       "      <td>20.437704</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.296008</td>\n",
       "      <td>-0.142416</td>\n",
       "      <td>26.657452</td>\n",
       "      <td>26.845801</td>\n",
       "      <td>21.094451</td>\n",
       "      <td>28.482447</td>\n",
       "      <td>-3.000038</td>\n",
       "      <td>-5.253792</td>\n",
       "      <td>6.692845</td>\n",
       "      <td>7.355366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.635787</td>\n",
       "      <td>-0.679125</td>\n",
       "      <td>-10.791860</td>\n",
       "      <td>13.123179</td>\n",
       "      <td>25.574548</td>\n",
       "      <td>32.136099</td>\n",
       "      <td>20.859789</td>\n",
       "      <td>15.460488</td>\n",
       "      <td>20.785099</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.857502</td>\n",
       "      <td>-7.066338</td>\n",
       "      <td>22.722743</td>\n",
       "      <td>29.849994</td>\n",
       "      <td>30.200593</td>\n",
       "      <td>-5.622287</td>\n",
       "      <td>8.211991</td>\n",
       "      <td>13.657285</td>\n",
       "      <td>7.778116</td>\n",
       "      <td>10.592168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.058552</td>\n",
       "      <td>-2.623195</td>\n",
       "      <td>26.745231</td>\n",
       "      <td>22.265812</td>\n",
       "      <td>3.441419</td>\n",
       "      <td>3.934305</td>\n",
       "      <td>-3.726288</td>\n",
       "      <td>-2.348845</td>\n",
       "      <td>17.311256</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.714819</td>\n",
       "      <td>12.211388</td>\n",
       "      <td>40.242840</td>\n",
       "      <td>20.876647</td>\n",
       "      <td>17.800351</td>\n",
       "      <td>5.946556</td>\n",
       "      <td>-22.282134</td>\n",
       "      <td>20.586275</td>\n",
       "      <td>23.964243</td>\n",
       "      <td>-2.485860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-10.069621</td>\n",
       "      <td>-8.714222</td>\n",
       "      <td>16.213594</td>\n",
       "      <td>3.487754</td>\n",
       "      <td>-8.008801</td>\n",
       "      <td>27.680261</td>\n",
       "      <td>3.248010</td>\n",
       "      <td>-1.967342</td>\n",
       "      <td>8.183699</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.197708</td>\n",
       "      <td>-5.610286</td>\n",
       "      <td>14.377007</td>\n",
       "      <td>21.418152</td>\n",
       "      <td>-7.947945</td>\n",
       "      <td>3.909288</td>\n",
       "      <td>-0.677026</td>\n",
       "      <td>-7.557458</td>\n",
       "      <td>14.940218</td>\n",
       "      <td>13.796720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>18.301973</td>\n",
       "      <td>14.657118</td>\n",
       "      <td>-11.845406</td>\n",
       "      <td>10.525305</td>\n",
       "      <td>17.020131</td>\n",
       "      <td>-0.417659</td>\n",
       "      <td>-2.370331</td>\n",
       "      <td>-10.648123</td>\n",
       "      <td>25.889483</td>\n",
       "      <td>...</td>\n",
       "      <td>1.196496</td>\n",
       "      <td>5.505215</td>\n",
       "      <td>7.663839</td>\n",
       "      <td>5.822160</td>\n",
       "      <td>24.019266</td>\n",
       "      <td>10.538759</td>\n",
       "      <td>7.596436</td>\n",
       "      <td>24.862538</td>\n",
       "      <td>38.692663</td>\n",
       "      <td>4.645963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0          1          2          3          4          5          6     \n",
       "0  0.0  -9.653245  12.503635   0.364683   8.849870  15.112630  13.802204  \\\n",
       "1  2.0   1.635787  -0.679125 -10.791860  13.123179  25.574548  32.136099   \n",
       "2  1.0   7.058552  -2.623195  26.745231  22.265812   3.441419   3.934305   \n",
       "3  1.0 -10.069621  -8.714222  16.213594   3.487754  -8.008801  27.680261   \n",
       "4  1.0  18.301973  14.657118 -11.845406  10.525305  17.020131  -0.417659   \n",
       "\n",
       "         7          8          9    ...       91         92         93    \n",
       "0  10.928423   3.953502  20.437704  ... -1.296008  -0.142416  26.657452  \\\n",
       "1  20.859789  15.460488  20.785099  ... -2.857502  -7.066338  22.722743   \n",
       "2  -3.726288  -2.348845  17.311256  ... -3.714819  12.211388  40.242840   \n",
       "3   3.248010  -1.967342   8.183699  ... -0.197708  -5.610286  14.377007   \n",
       "4  -2.370331 -10.648123  25.889483  ...  1.196496   5.505215   7.663839   \n",
       "\n",
       "         94         95         96         97         98         99         100  \n",
       "0  26.845801  21.094451  28.482447  -3.000038  -5.253792   6.692845   7.355366  \n",
       "1  29.849994  30.200593  -5.622287   8.211991  13.657285   7.778116  10.592168  \n",
       "2  20.876647  17.800351   5.946556 -22.282134  20.586275  23.964243  -2.485860  \n",
       "3  21.418152  -7.947945   3.909288  -0.677026  -7.557458  14.940218  13.796720  \n",
       "4   5.822160  24.019266  10.538759   7.596436  24.862538  38.692663   4.645963  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataset.iloc[:, 0].sort_values().unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_dataset = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/fg-research/lstm-fcn-sagemaker/master/data/training/valid.csv\",\n",
    "    header=None,\n",
    "    index_col=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 101)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>15.478889</td>\n",
       "      <td>6.773570</td>\n",
       "      <td>-10.307197</td>\n",
       "      <td>24.924477</td>\n",
       "      <td>19.201765</td>\n",
       "      <td>16.836480</td>\n",
       "      <td>-8.235487</td>\n",
       "      <td>-9.037011</td>\n",
       "      <td>13.581153</td>\n",
       "      <td>...</td>\n",
       "      <td>-18.169935</td>\n",
       "      <td>12.032606</td>\n",
       "      <td>17.552417</td>\n",
       "      <td>14.037278</td>\n",
       "      <td>6.454744</td>\n",
       "      <td>-14.332159</td>\n",
       "      <td>13.894731</td>\n",
       "      <td>7.677091</td>\n",
       "      <td>24.552010</td>\n",
       "      <td>0.380896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>22.591914</td>\n",
       "      <td>18.728685</td>\n",
       "      <td>3.226004</td>\n",
       "      <td>10.545205</td>\n",
       "      <td>41.212151</td>\n",
       "      <td>20.576582</td>\n",
       "      <td>0.406792</td>\n",
       "      <td>11.362842</td>\n",
       "      <td>6.217928</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064311</td>\n",
       "      <td>3.098154</td>\n",
       "      <td>23.039155</td>\n",
       "      <td>17.979268</td>\n",
       "      <td>9.616904</td>\n",
       "      <td>-13.297607</td>\n",
       "      <td>-8.835471</td>\n",
       "      <td>18.541289</td>\n",
       "      <td>25.855706</td>\n",
       "      <td>7.395281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.651071</td>\n",
       "      <td>-2.657937</td>\n",
       "      <td>3.648929</td>\n",
       "      <td>7.510428</td>\n",
       "      <td>37.409361</td>\n",
       "      <td>34.633973</td>\n",
       "      <td>23.413473</td>\n",
       "      <td>25.917828</td>\n",
       "      <td>14.415751</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.787993</td>\n",
       "      <td>1.625704</td>\n",
       "      <td>18.428298</td>\n",
       "      <td>-5.561938</td>\n",
       "      <td>35.923486</td>\n",
       "      <td>19.942426</td>\n",
       "      <td>26.873630</td>\n",
       "      <td>-1.828905</td>\n",
       "      <td>6.985897</td>\n",
       "      <td>0.851959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.838490</td>\n",
       "      <td>-17.546395</td>\n",
       "      <td>15.898714</td>\n",
       "      <td>22.614802</td>\n",
       "      <td>23.301109</td>\n",
       "      <td>23.542851</td>\n",
       "      <td>16.769920</td>\n",
       "      <td>15.424828</td>\n",
       "      <td>-9.275713</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.446913</td>\n",
       "      <td>-7.111415</td>\n",
       "      <td>21.063856</td>\n",
       "      <td>30.736190</td>\n",
       "      <td>20.752074</td>\n",
       "      <td>18.309628</td>\n",
       "      <td>4.356676</td>\n",
       "      <td>17.463315</td>\n",
       "      <td>-1.107846</td>\n",
       "      <td>19.377706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>18.064992</td>\n",
       "      <td>11.531259</td>\n",
       "      <td>6.296674</td>\n",
       "      <td>-4.855813</td>\n",
       "      <td>9.530433</td>\n",
       "      <td>13.590807</td>\n",
       "      <td>-6.319849</td>\n",
       "      <td>-8.786876</td>\n",
       "      <td>14.091134</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.266969</td>\n",
       "      <td>9.832693</td>\n",
       "      <td>4.932949</td>\n",
       "      <td>32.174798</td>\n",
       "      <td>8.449398</td>\n",
       "      <td>-5.938063</td>\n",
       "      <td>9.212065</td>\n",
       "      <td>16.015061</td>\n",
       "      <td>27.147949</td>\n",
       "      <td>-10.010569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0          1          2          3          4          5          6     \n",
       "0  1.0  15.478889   6.773570 -10.307197  24.924477  19.201765  16.836480  \\\n",
       "1  1.0  22.591914  18.728685   3.226004  10.545205  41.212151  20.576582   \n",
       "2  0.0   2.651071  -2.657937   3.648929   7.510428  37.409361  34.633973   \n",
       "3  2.0  -1.838490 -17.546395  15.898714  22.614802  23.301109  23.542851   \n",
       "4  1.0  18.064992  11.531259   6.296674  -4.855813   9.530433  13.590807   \n",
       "\n",
       "         7          8          9    ...        91         92         93    \n",
       "0  -8.235487  -9.037011  13.581153  ... -18.169935  12.032606  17.552417  \\\n",
       "1   0.406792  11.362842   6.217928  ...   0.064311   3.098154  23.039155   \n",
       "2  23.413473  25.917828  14.415751  ... -12.787993   1.625704  18.428298   \n",
       "3  16.769920  15.424828  -9.275713  ... -13.446913  -7.111415  21.063856   \n",
       "4  -6.319849  -8.786876  14.091134  ...  -8.266969   9.832693   4.932949   \n",
       "\n",
       "         94         95         96         97         98         99         100  \n",
       "0  14.037278   6.454744 -14.332159  13.894731   7.677091  24.552010   0.380896  \n",
       "1  17.979268   9.616904 -13.297607  -8.835471  18.541289  25.855706   7.395281  \n",
       "2  -5.561938  35.923486  19.942426  26.873630  -1.828905   6.985897   0.851959  \n",
       "3  30.736190  20.752074  18.309628   4.356676  17.463315  -1.107846  19.377706  \n",
       "4  32.174798   8.449398  -5.938063   9.212065  16.015061  27.147949 -10.010569  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_dataset.iloc[:, 0].sort_values().unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Upload datasets to Amazon S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_data = sagemaker_session.upload_string_as_file_body(\n",
    "    body=training_dataset.to_csv(index=False, header=False),\n",
    "    bucket=bucket, \n",
    "    key=\"lstm-fcn-algo/data/training/input/train.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-eu-west-1-661670223746/lstm-fcn-algo/data/training/input/train.csv'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_data = sagemaker_session.upload_string_as_file_body(\n",
    "    body=validation_dataset.to_csv(index=False, header=False),\n",
    "    bucket=bucket, \n",
    "    key=\"lstm-fcn-algo/data/training/input/valid.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-eu-west-1-661670223746/lstm-fcn-algo/data/training/input/valid.csv'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3: Train a machine learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that dataset is available in an accessible Amazon S3 bucket, we are ready to train a machine learning model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Train a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that the sample dataset is relatively small, we keep the number of parameters low and we run the training for only a few epochs. \n",
    "\n",
    "You can find more information about the model's hyperparameters in the **Hyperparameters** section of the algorithm listing page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define hyperparameters\n",
    "hyperparameters = {\n",
    "    \"units\": 8,\n",
    "    \"dropout\": 0.8,\n",
    "    \"filters-1\": 4,\n",
    "    \"filters-2\": 4,\n",
    "    \"filters-3\": 4,\n",
    "    \"kernel-size-1\": 3,\n",
    "    \"kernel-size-2\": 3,\n",
    "    \"kernel-size-3\": 3,\n",
    "    \"batch-size\": 64,\n",
    "    \"lr\": 0.001,\n",
    "    \"epochs\": 10,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For information on creating an `Estimator` object, see the [documentation](https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: lstm-fcn-training-2023-07-21-18-50-04-621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-21 18:50:04 Starting - Starting the training job...\n",
      "2023-07-21 18:50:19 Starting - Preparing the instances for training......\n",
      "2023-07-21 18:51:31 Downloading - Downloading input data\n",
      "2023-07-21 18:51:31 Training - Downloading the training image..............................\n",
      "2023-07-21 18:56:27 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2023-07-21 18:56:33,238 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2023-07-21 18:56:33,239 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-07-21 18:56:33,240 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-07-21 18:56:33,249 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2023-07-21 18:56:33,255 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2023-07-21 18:56:35,097 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-07-21 18:56:35,098 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-07-21 18:56:35,115 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-07-21 18:56:35,115 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-07-21 18:56:35,125 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-07-21 18:56:35,126 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-07-21 18:56:35,135 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\",\n",
      "        \"validation\": \"/opt/ml/input/data/validation\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.m5.xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch-size\": 64,\n",
      "        \"dropout\": 0.8,\n",
      "        \"epochs\": 10,\n",
      "        \"filters-1\": 4,\n",
      "        \"filters-2\": 4,\n",
      "        \"filters-3\": 4,\n",
      "        \"kernel-size-1\": 3,\n",
      "        \"kernel-size-2\": 3,\n",
      "        \"kernel-size-3\": 3,\n",
      "        \"lr\": 0.001,\n",
      "        \"units\": 8\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"validation\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.m5.xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": true,\n",
      "    \"job_name\": \"lstm-fcn-training-2023-07-21-18-50-04-621\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"/opt/ml/code\",\n",
      "    \"module_name\": \"training\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m5.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"training.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch-size\":64,\"dropout\":0.8,\"epochs\":10,\"filters-1\":4,\"filters-2\":4,\"filters-3\":4,\"kernel-size-1\":3,\"kernel-size-2\":3,\"kernel-size-3\":3,\"lr\":0.001,\"units\":8}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=training.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\",\"validation\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.m5.xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=training\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=/opt/ml/code\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.m5.xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch-size\":64,\"dropout\":0.8,\"epochs\":10,\"filters-1\":4,\"filters-2\":4,\"filters-3\":4,\"kernel-size-1\":3,\"kernel-size-2\":3,\"kernel-size-3\":3,\"lr\":0.001,\"units\":8},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":true,\"job_name\":\"lstm-fcn-training-2023-07-21-18-50-04-621\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"training\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"training.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch-size\",\"64\",\"--dropout\",\"0.8\",\"--epochs\",\"10\",\"--filters-1\",\"4\",\"--filters-2\",\"4\",\"--filters-3\",\"4\",\"--kernel-size-1\",\"3\",\"--kernel-size-2\",\"3\",\"--kernel-size-3\",\"3\",\"--lr\",\"0.001\",\"--units\",\"8\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH-SIZE=64\u001b[0m\n",
      "\u001b[34mSM_HP_DROPOUT=0.8\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=10\u001b[0m\n",
      "\u001b[34mSM_HP_FILTERS-1=4\u001b[0m\n",
      "\u001b[34mSM_HP_FILTERS-2=4\u001b[0m\n",
      "\u001b[34mSM_HP_FILTERS-3=4\u001b[0m\n",
      "\u001b[34mSM_HP_KERNEL-SIZE-1=3\u001b[0m\n",
      "\u001b[34mSM_HP_KERNEL-SIZE-2=3\u001b[0m\n",
      "\u001b[34mSM_HP_KERNEL-SIZE-3=3\u001b[0m\n",
      "\u001b[34mSM_HP_LR=0.001\u001b[0m\n",
      "\u001b[34mSM_HP_UNITS=8\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python310.zip:/opt/conda/lib/python3.10:/opt/conda/lib/python3.10/lib-dynload:/opt/conda/lib/python3.10/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.10 training.py --batch-size 64 --dropout 0.8 --epochs 10 --filters-1 4 --filters-2 4 --filters-3 4 --kernel-size-1 3 --kernel-size-2 3 --kernel-size-3 3 --lr 0.001 --units 8\u001b[0m\n",
      "\u001b[34m2023-07-21 18:56:35,194 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34m--------------------------------------\u001b[0m\n",
      "\u001b[34mTraining on 700 time series.\u001b[0m\n",
      "\u001b[34mTime series length: 100\u001b[0m\n",
      "\u001b[34mTime series labels: [0, 1, 2]\u001b[0m\n",
      "\u001b[34m--------------------------------------\u001b[0m\n",
      "\u001b[34m--------------------------------------\u001b[0m\n",
      "\u001b[34mValidating on 150 time series.\u001b[0m\n",
      "\u001b[34mTime series length: 100\u001b[0m\n",
      "\u001b[34mTime series labels: [0, 1, 2]\u001b[0m\n",
      "\u001b[34m--------------------------------------\u001b[0m\n",
      "\u001b[34m--------------------------------------\u001b[0m\n",
      "\u001b[34mTraining the model.\u001b[0m\n",
      "\u001b[34m--------------------------------------\u001b[0m\n",
      "\u001b[34mEpoch: 1, Training Loss: 0.0173, Training Accuracy: 0.3343, Validation Loss: 0.0221, Validation Accuracy: 0.3333\u001b[0m\n",
      "\u001b[34mEpoch: 2, Training Loss: 0.0171, Training Accuracy: 0.3371, Validation Loss: 0.0219, Validation Accuracy: 0.3400\u001b[0m\n",
      "\u001b[34mEpoch: 3, Training Loss: 0.0169, Training Accuracy: 0.3900, Validation Loss: 0.0216, Validation Accuracy: 0.3800\u001b[0m\n",
      "\u001b[34mEpoch: 4, Training Loss: 0.0167, Training Accuracy: 0.5814, Validation Loss: 0.0213, Validation Accuracy: 0.5133\u001b[0m\n",
      "\u001b[34mEpoch: 5, Training Loss: 0.0164, Training Accuracy: 0.7271, Validation Loss: 0.0210, Validation Accuracy: 0.7333\u001b[0m\n",
      "\u001b[34mEpoch: 6, Training Loss: 0.0161, Training Accuracy: 0.7529, Validation Loss: 0.0207, Validation Accuracy: 0.7400\u001b[0m\n",
      "\u001b[34mEpoch: 7, Training Loss: 0.0157, Training Accuracy: 0.8514, Validation Loss: 0.0201, Validation Accuracy: 0.8467\u001b[0m\n",
      "\u001b[34mEpoch: 8, Training Loss: 0.0153, Training Accuracy: 0.8586, Validation Loss: 0.0196, Validation Accuracy: 0.8733\u001b[0m\n",
      "\u001b[34mEpoch: 9, Training Loss: 0.0148, Training Accuracy: 0.9000, Validation Loss: 0.0191, Validation Accuracy: 0.8933\u001b[0m\n",
      "\u001b[34mEpoch: 10, Training Loss: 0.0143, Training Accuracy: 0.9057, Validation Loss: 0.0185, Validation Accuracy: 0.9000\u001b[0m\n",
      "\u001b[34m--------------------------------------\u001b[0m\n",
      "\u001b[34mScoring the model.\u001b[0m\n",
      "\u001b[34mtrain:loss 0.0143\u001b[0m\n",
      "\u001b[34mtrain:acc 0.9057\u001b[0m\n",
      "\u001b[34mvalid:loss 0.0185\u001b[0m\n",
      "\u001b[34mvalid:acc 0.9000\u001b[0m\n",
      "\u001b[34m--------------------------------------\u001b[0m\n",
      "\u001b[34m2023-07-21 18:56:38,771 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2023-07-21 18:56:38,771 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2023-07-21 18:56:38,771 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2023-07-21 18:56:59 Uploading - Uploading generated training model\n",
      "2023-07-21 18:56:59 Completed - Training job completed\n",
      "Training seconds: 353\n",
      "Billable seconds: 353\n"
     ]
    }
   ],
   "source": [
    "# create an estimator object for running a training job\n",
    "estimator = sagemaker.algorithm.AlgorithmEstimator(\n",
    "    algorithm_arn=algo_arn,\n",
    "    base_job_name=\"lstm-fcn-training\",\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    input_mode=\"File\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    hyperparameters=hyperparameters,\n",
    ")\n",
    "\n",
    "# run the training job\n",
    "estimator.fit({\"training\": training_data, \"validation\": validation_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See this [blog-post](https://aws.amazon.com/blogs/machine-learning/easily-monitor-and-visualize-metrics-while-training-models-on-amazon-sagemaker/) for more information how to visualize metrics during the process. You can also open the training job from [Amazon SageMaker console](https://console.aws.amazon.com/sagemaker/home?#/jobs/) and monitor the metrics/logs in **Monitor** section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4: Deploy model and verify results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can deploy the model for performing real-time inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Deploy trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model package with name: lstm-fcn-training-2023-07-21-18-57-19-009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: lstm-fcn-training-2023-07-21-18-57-19-009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating endpoint-config with name lstm-fcn-training-2023-07-21-18-57-19-009\n",
      "INFO:sagemaker:Creating endpoint with name lstm-fcn-training-2023-07-21-18-57-19-009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------!"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    serializer=sagemaker.serializers.CSVSerializer(content_type=\"text/csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the endpoint is in service, you can perform real-time inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Create input payload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inference algorithm takes as input a CSV file containing the time series.\n",
    "Each row of the CSV file represents a time series, while each column represents a time step.\n",
    "The CSV file should not contain any index column or column headers.\n",
    "All time series should have the same length and should not contain missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/fg-research/lstm-fcn-sagemaker/master/data/inference/input/test_data.csv\",\n",
    "    header=None,\n",
    "    index_col=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 100)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.922934</td>\n",
       "      <td>-12.333286</td>\n",
       "      <td>16.970006</td>\n",
       "      <td>20.459903</td>\n",
       "      <td>10.755518</td>\n",
       "      <td>5.953969</td>\n",
       "      <td>15.223849</td>\n",
       "      <td>9.021735</td>\n",
       "      <td>7.018893</td>\n",
       "      <td>11.261269</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.807806</td>\n",
       "      <td>-11.919346</td>\n",
       "      <td>11.581619</td>\n",
       "      <td>32.449001</td>\n",
       "      <td>2.507668</td>\n",
       "      <td>10.808019</td>\n",
       "      <td>1.193405</td>\n",
       "      <td>33.232719</td>\n",
       "      <td>42.003243</td>\n",
       "      <td>20.314625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.305337</td>\n",
       "      <td>-5.799543</td>\n",
       "      <td>28.457907</td>\n",
       "      <td>27.666659</td>\n",
       "      <td>10.818559</td>\n",
       "      <td>18.721389</td>\n",
       "      <td>20.306512</td>\n",
       "      <td>21.298879</td>\n",
       "      <td>6.722657</td>\n",
       "      <td>-8.661484</td>\n",
       "      <td>...</td>\n",
       "      <td>9.424779</td>\n",
       "      <td>-7.549842</td>\n",
       "      <td>10.220740</td>\n",
       "      <td>23.419116</td>\n",
       "      <td>17.119124</td>\n",
       "      <td>16.169222</td>\n",
       "      <td>11.892821</td>\n",
       "      <td>-1.325216</td>\n",
       "      <td>13.686307</td>\n",
       "      <td>-10.180377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.141899</td>\n",
       "      <td>-11.770865</td>\n",
       "      <td>-0.760004</td>\n",
       "      <td>42.355950</td>\n",
       "      <td>17.172389</td>\n",
       "      <td>26.767570</td>\n",
       "      <td>-7.531622</td>\n",
       "      <td>-1.133515</td>\n",
       "      <td>20.472634</td>\n",
       "      <td>-3.463446</td>\n",
       "      <td>...</td>\n",
       "      <td>-27.063771</td>\n",
       "      <td>0.814035</td>\n",
       "      <td>17.655639</td>\n",
       "      <td>22.273710</td>\n",
       "      <td>0.180531</td>\n",
       "      <td>13.680891</td>\n",
       "      <td>16.564715</td>\n",
       "      <td>3.861534</td>\n",
       "      <td>2.558995</td>\n",
       "      <td>-3.174557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-18.277705</td>\n",
       "      <td>-19.144148</td>\n",
       "      <td>1.763139</td>\n",
       "      <td>21.252543</td>\n",
       "      <td>26.622625</td>\n",
       "      <td>27.344010</td>\n",
       "      <td>7.139832</td>\n",
       "      <td>17.754067</td>\n",
       "      <td>16.333792</td>\n",
       "      <td>-0.494965</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.311305</td>\n",
       "      <td>14.902996</td>\n",
       "      <td>26.646289</td>\n",
       "      <td>19.877144</td>\n",
       "      <td>31.825011</td>\n",
       "      <td>11.897166</td>\n",
       "      <td>1.253178</td>\n",
       "      <td>-4.224470</td>\n",
       "      <td>19.184084</td>\n",
       "      <td>-7.240560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.431898</td>\n",
       "      <td>-11.903490</td>\n",
       "      <td>-3.126534</td>\n",
       "      <td>25.505996</td>\n",
       "      <td>36.183348</td>\n",
       "      <td>15.120651</td>\n",
       "      <td>3.765192</td>\n",
       "      <td>1.706296</td>\n",
       "      <td>23.100381</td>\n",
       "      <td>19.476364</td>\n",
       "      <td>...</td>\n",
       "      <td>-20.407485</td>\n",
       "      <td>-3.496949</td>\n",
       "      <td>-7.278537</td>\n",
       "      <td>31.580566</td>\n",
       "      <td>30.925944</td>\n",
       "      <td>25.387130</td>\n",
       "      <td>4.938499</td>\n",
       "      <td>15.018984</td>\n",
       "      <td>11.352280</td>\n",
       "      <td>18.085493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0          1          2          3          4          5    \n",
       "0  13.922934 -12.333286  16.970006  20.459903  10.755518   5.953969  \\\n",
       "1   2.305337  -5.799543  28.457907  27.666659  10.818559  18.721389   \n",
       "2  13.141899 -11.770865  -0.760004  42.355950  17.172389  26.767570   \n",
       "3 -18.277705 -19.144148   1.763139  21.252543  26.622625  27.344010   \n",
       "4  -2.431898 -11.903490  -3.126534  25.505996  36.183348  15.120651   \n",
       "\n",
       "          6          7          8          9   ...         90         91   \n",
       "0  15.223849   9.021735   7.018893  11.261269  ...  -6.807806 -11.919346  \\\n",
       "1  20.306512  21.298879   6.722657  -8.661484  ...   9.424779  -7.549842   \n",
       "2  -7.531622  -1.133515  20.472634  -3.463446  ... -27.063771   0.814035   \n",
       "3   7.139832  17.754067  16.333792  -0.494965  ... -11.311305  14.902996   \n",
       "4   3.765192   1.706296  23.100381  19.476364  ... -20.407485  -3.496949   \n",
       "\n",
       "          92         93         94         95         96         97   \n",
       "0  11.581619  32.449001   2.507668  10.808019   1.193405  33.232719  \\\n",
       "1  10.220740  23.419116  17.119124  16.169222  11.892821  -1.325216   \n",
       "2  17.655639  22.273710   0.180531  13.680891  16.564715   3.861534   \n",
       "3  26.646289  19.877144  31.825011  11.897166   1.253178  -4.224470   \n",
       "4  -7.278537  31.580566  30.925944  25.387130   4.938499  15.018984   \n",
       "\n",
       "          98         99  \n",
       "0  42.003243  20.314625  \n",
       "1  13.686307 -10.180377  \n",
       "2   2.558995  -3.174557  \n",
       "3  19.184084  -7.240560  \n",
       "4  11.352280  18.085493  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_data = sagemaker_session.upload_string_as_file_body(\n",
    "    body=test_dataset.to_csv(index=False, header=False),\n",
    "    bucket=bucket, \n",
    "    key=\"lstm-fcn-algo/data/inference/input/test_data.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "payload = sagemaker_session.read_s3_file(\n",
    "    bucket=bucket, \n",
    "    key_prefix=\"lstm-fcn-algo/data/inference/input/test_data.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Perform real-time inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'RequestId': '578a825a-2345-449b-9efa-2770a91ef093', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '578a825a-2345-449b-9efa-2770a91ef093', 'x-amzn-invoked-production-variant': 'AllTraffic', 'date': 'Fri, 21 Jul 2023 19:03:07 GMT', 'content-type': 'application/json', 'content-length': '300', 'connection': 'keep-alive'}, 'RetryAttempts': 0}, 'ContentType': 'application/json', 'InvokedProductionVariant': 'AllTraffic', 'Body': <botocore.response.StreamingBody object at 0x7f27a2d6eda0>}\n"
     ]
    }
   ],
   "source": [
    "response = sagemaker_session.sagemaker_runtime_client.invoke_endpoint(\n",
    "    EndpointName=predictor.endpoint_name,\n",
    "    ContentType='text/csv',\n",
    "    Body=payload\n",
    ")\n",
    "print(response)\n",
    "real_time_predictions = response['Body'].read().decode('utf-8').split('\\n')[:-1]\n",
    "real_time_predictions = pd.DataFrame(real_time_predictions).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "real_time_results = sagemaker_session.upload_string_as_file_body(\n",
    "    body=real_time_predictions.to_csv(index=False, header=False),\n",
    "    bucket=bucket, \n",
    "    key=\"lstm-fcn-algo/data/inference/output/real-time/real_time_predictions.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-eu-west-1-661670223746/lstm-fcn-algo/data/inference/output/real-time/real_time_predictions.csv'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_time_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Visualize output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inference algorithm outputs the predicted class labels in the same format as they were provided for training, that is as integers from `0` to `N - 1`, where `N` is the number of classes. The predicted class labels are returned in CSV format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_time_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "0  1.0\n",
       "1  0.0\n",
       "2  2.0\n",
       "3  2.0\n",
       "4  2.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_time_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 2.]\n"
     ]
    }
   ],
   "source": [
    "print(real_time_predictions.iloc[:, 0].sort_values().unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Calculate relevant metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ground truth test labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_labels = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/fg-research/lstm-fcn-sagemaker/master/data/inference/output/ground-truth/test_labels.csv\",\n",
    "    header=None,\n",
    "    index_col=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "0  1.0\n",
       "1  0.0\n",
       "2  2.0\n",
       "3  2.0\n",
       "4  2.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 2.]\n"
     ]
    }
   ],
   "source": [
    "print(test_labels.iloc[:, 0].sort_values().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_true=test_labels.iloc[:, 0], y_pred=real_time_predictions.iloc[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.938776</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.936382</td>\n",
       "      <td>0.936382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.929293</td>\n",
       "      <td>0.969072</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.934070</td>\n",
       "      <td>0.934070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0.0        1.0        2.0  accuracy   macro avg  weighted avg\n",
       "precision   0.938776   1.000000   0.870370  0.933333    0.936382      0.936382\n",
       "recall      0.920000   0.940000   0.940000  0.933333    0.933333      0.933333\n",
       "f1-score    0.929293   0.969072   0.903846  0.933333    0.934070      0.934070\n",
       "support    50.000000  50.000000  50.000000  0.933333  150.000000    150.000000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(classification_report(y_true=test_labels.iloc[:, 0], y_pred=real_time_predictions.iloc[:, 0], output_dict=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If [Amazon SageMaker Model Monitor](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor.html) supports the type of problem you are trying to solve using this algorithm, use the following examples to add Model Monitor support to your product.\n",
    "For sample code to enable and monitor the model, see following notebooks:\n",
    "1. [Enable Amazon SageMaker Model Monitor](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/sagemaker_model_monitor/enable_model_monitor/SageMaker-Enable-Model-Monitor.ipynb)\n",
    "2. [Amazon SageMaker Model Monitor - visualizing monitoring results](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/sagemaker_model_monitor/visualization/SageMaker-Model-Monitor-Visualize.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F. Delete the endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have successfully performed a real-time inference, you do not need the endpoint any more. You can terminate the same to avoid being charged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting endpoint configuration with name: lstm-fcn-training-2023-07-21-18-57-19-009\n",
      "INFO:sagemaker:Deleting endpoint with name: lstm-fcn-training-2023-07-21-18-57-19-009\n"
     ]
    }
   ],
   "source": [
    "predictor.delete_endpoint(delete_endpoint_config=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is an experiment, you do not need to run a hyperparameter tuning job. However, if you would like to see how to tune a model trained using a third-party algorithm with Amazon SageMaker's hyperparameter tuning functionality, you can run the optional tuning step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5: Tune your model! (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Tuning Guidelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has the following hyperparameters, all of which are tunable:\n",
    "- `units`: `int`. The number of units of the LSTM layer (default = 8).\n",
    "- `dropout`: `float`. The rate of the dropout layer (default = 0.8).\n",
    "- `filters-1`: `int`. The number of filters of the first convolutional layer (default = 128).\n",
    "- `filters-2`: `int`. The number of filters of the second convolutional layer (default = 256).\n",
    "- `filters-3`: `int`. The number of filters of the third convolutional layer (default = 128).\n",
    "- `kernel-size-1`: `int`. The size of the kernel of the first convolutional layer (default = 8).\n",
    "- `kernel-size-2`: `int`. The size of the kernel of the second convolutional layer (default = 5).\n",
    "- `kernel-size-3`: `int`. The size of the kernel of the third convolutional layer (default = 3).\n",
    "- `lr`: `float`. The learning rate used for training (default = 0.001).\n",
    "- `batch-size`: `int`. The batch size used for training (default = 128).\n",
    "- `epochs`: `int`. The number of training epochs (default = 2000)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Define Tuning configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that the sample dataset is relatively small, we keep the number of parameters low and we run the training for only a few epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperparameter_ranges = {\n",
    "    \"units\": sagemaker.parameter.IntegerParameter(4, 16),\n",
    "    \"dropout\": sagemaker.parameter.ContinuousParameter(0.1, 0.9),\n",
    "    \"filters-1\": sagemaker.parameter.IntegerParameter(4, 16),\n",
    "    \"filters-2\": sagemaker.parameter.IntegerParameter(4, 16),\n",
    "    \"filters-3\": sagemaker.parameter.IntegerParameter(4, 16),\n",
    "    \"kernel-size-1\": sagemaker.parameter.IntegerParameter(3, 7),\n",
    "    \"kernel-size-2\": sagemaker.parameter.IntegerParameter(3, 7),\n",
    "    \"kernel-size-3\": sagemaker.parameter.IntegerParameter(3, 7),\n",
    "    \"lr\": sagemaker.parameter.ContinuousParameter(0.0001, 0.001),\n",
    "    \"batch-size\": sagemaker.parameter.CategoricalParameter([32, 64, 128]),\n",
    "    \"epochs\": sagemaker.parameter.IntegerParameter(5, 10),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the validation accuracy as the objective to be maximized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "objective_metric_name = \"valid:acc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "objective_type = \"Maximize\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Run a model tuning job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the interest of time, we run the tuner only for a few iterations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tuner = sagemaker.tuner.HyperparameterTuner(\n",
    "    estimator=estimator,\n",
    "    base_tuning_job_name=\"lstm-fcn-tuning\",\n",
    "    objective_metric_name=objective_metric_name,\n",
    "    objective_type=objective_type,\n",
    "    hyperparameter_ranges=hyperparameter_ranges,\n",
    "    max_jobs=4,\n",
    "    max_parallel_jobs=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating hyperparameter tuning job with name: lstm-fcn-tuning-230721-1903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........................................................................................!\n"
     ]
    }
   ],
   "source": [
    "tuner.fit({\"training\": training_data, \"validation\": validation_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch-size</th>\n",
       "      <th>dropout</th>\n",
       "      <th>epochs</th>\n",
       "      <th>filters-1</th>\n",
       "      <th>filters-2</th>\n",
       "      <th>filters-3</th>\n",
       "      <th>kernel-size-1</th>\n",
       "      <th>kernel-size-2</th>\n",
       "      <th>kernel-size-3</th>\n",
       "      <th>lr</th>\n",
       "      <th>units</th>\n",
       "      <th>TrainingJobName</th>\n",
       "      <th>TrainingJobStatus</th>\n",
       "      <th>FinalObjectiveValue</th>\n",
       "      <th>TrainingStartTime</th>\n",
       "      <th>TrainingEndTime</th>\n",
       "      <th>TrainingElapsedTimeSeconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128.0</td>\n",
       "      <td>0.445160</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000957</td>\n",
       "      <td>14.0</td>\n",
       "      <td>lstm-fcn-tuning-230721-1903-004-7b20c3ab</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>2023-07-21 19:04:26+00:00</td>\n",
       "      <td>2023-07-21 19:09:49+00:00</td>\n",
       "      <td>323.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128.0</td>\n",
       "      <td>0.285118</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000910</td>\n",
       "      <td>6.0</td>\n",
       "      <td>lstm-fcn-tuning-230721-1903-003-099f4dcb</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.8267</td>\n",
       "      <td>2023-07-21 19:04:18+00:00</td>\n",
       "      <td>2023-07-21 19:09:45+00:00</td>\n",
       "      <td>327.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32.0</td>\n",
       "      <td>0.812971</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000676</td>\n",
       "      <td>5.0</td>\n",
       "      <td>lstm-fcn-tuning-230721-1903-002-935b558b</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.7333</td>\n",
       "      <td>2023-07-21 19:04:14+00:00</td>\n",
       "      <td>2023-07-21 19:09:52+00:00</td>\n",
       "      <td>338.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32.0</td>\n",
       "      <td>0.633893</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000982</td>\n",
       "      <td>5.0</td>\n",
       "      <td>lstm-fcn-tuning-230721-1903-001-b8ee5a2d</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.8800</td>\n",
       "      <td>2023-07-21 19:04:12+00:00</td>\n",
       "      <td>2023-07-21 19:09:50+00:00</td>\n",
       "      <td>338.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   batch-size   dropout  epochs  filters-1  filters-2  filters-3   \n",
       "0       128.0  0.445160     6.0       13.0        6.0        5.0  \\\n",
       "1       128.0  0.285118    10.0        4.0        4.0        4.0   \n",
       "2        32.0  0.812971     5.0       11.0       14.0       12.0   \n",
       "3        32.0  0.633893     8.0       16.0       13.0       13.0   \n",
       "\n",
       "   kernel-size-1  kernel-size-2  kernel-size-3        lr  units   \n",
       "0            4.0            4.0            6.0  0.000957   14.0  \\\n",
       "1            7.0            4.0            6.0  0.000910    6.0   \n",
       "2            6.0            5.0            3.0  0.000676    5.0   \n",
       "3            7.0            5.0            4.0  0.000982    5.0   \n",
       "\n",
       "                            TrainingJobName TrainingJobStatus   \n",
       "0  lstm-fcn-tuning-230721-1903-004-7b20c3ab         Completed  \\\n",
       "1  lstm-fcn-tuning-230721-1903-003-099f4dcb         Completed   \n",
       "2  lstm-fcn-tuning-230721-1903-002-935b558b         Completed   \n",
       "3  lstm-fcn-tuning-230721-1903-001-b8ee5a2d         Completed   \n",
       "\n",
       "   FinalObjectiveValue         TrainingStartTime           TrainingEndTime   \n",
       "0               0.8333 2023-07-21 19:04:26+00:00 2023-07-21 19:09:49+00:00  \\\n",
       "1               0.8267 2023-07-21 19:04:18+00:00 2023-07-21 19:09:45+00:00   \n",
       "2               0.7333 2023-07-21 19:04:14+00:00 2023-07-21 19:09:52+00:00   \n",
       "3               0.8800 2023-07-21 19:04:12+00:00 2023-07-21 19:09:50+00:00   \n",
       "\n",
       "   TrainingElapsedTimeSeconds  \n",
       "0                       323.0  \n",
       "1                       327.0  \n",
       "2                       338.0  \n",
       "3                       338.0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.analytics().dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have completed a tuning job (or even while the job is still running), you can [clone and use this notebook](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/hyperparameter_tuning/analyze_results/HPO_Analyze_TuningJob_Results.ipynb) to analyze the results to understand how each hyperparameter effects the quality of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Perform Batch inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you will perform batch inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model package with name: lstm-fcn-algo-2023-07-21-19-10-43-645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: lstm-fcn-algo-2023-07-21-19-10-43-645-2023-07-21-19-11-29-048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "transformer = estimator.transformer(\n",
    "    instance_count=1, \n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating transform job with name: lstm-fcn-training-2023-07-21-19-11-29-799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".............................................\u001b[34mWarning: TorchServe is using non-default JVM parameters: -XX:-UseContainerSupport\u001b[0m\n",
      "\u001b[34mWARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:03,706 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:03,767 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:03,876 [INFO ] main org.pytorch.serve.ModelServer - \u001b[0m\n",
      "\u001b[34mTorchserve version: 0.8.0\u001b[0m\n",
      "\u001b[34mTS Home: /opt/conda/lib/python3.10/site-packages\u001b[0m\n",
      "\u001b[34mCurrent directory: /\u001b[0m\n",
      "\u001b[34mTemp directory: /home/model-server/tmp\u001b[0m\n",
      "\u001b[34mMetrics config path: /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml\u001b[0m\n",
      "\u001b[34mNumber of GPUs: 0\u001b[0m\n",
      "\u001b[34mNumber of CPUs: 4\u001b[0m\n",
      "\u001b[34mMax heap size: 3934 M\u001b[0m\n",
      "\u001b[34mPython executable: /opt/conda/bin/python3.10\u001b[0m\n",
      "\u001b[34mConfig file: /etc/sagemaker-ts.properties\u001b[0m\n",
      "\u001b[34mInference address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34mManagement address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34mMetrics address: http://127.0.0.1:8082\u001b[0m\n",
      "\u001b[34mModel Store: /.sagemaker/ts/models\u001b[0m\n",
      "\u001b[34mInitial Models: model=/opt/ml/model\u001b[0m\n",
      "\u001b[34mLog dir: /logs\u001b[0m\n",
      "\u001b[34mMetrics dir: /logs\u001b[0m\n",
      "\u001b[34mNetty threads: 0\u001b[0m\n",
      "\u001b[34mNetty client threads: 0\u001b[0m\n",
      "\u001b[34mDefault workers per model: 4\u001b[0m\n",
      "\u001b[34mBlacklist Regex: N/A\u001b[0m\n",
      "\u001b[34mMaximum Response Size: 6553500\u001b[0m\n",
      "\u001b[34mMaximum Request Size: 6553500\u001b[0m\n",
      "\u001b[34mLimit Maximum Image Pixels: true\u001b[0m\n",
      "\u001b[34mPrefer direct buffer: false\u001b[0m\n",
      "\u001b[34mAllowed Urls: [file://.*|http(s)?://.*]\u001b[0m\n",
      "\u001b[34mCustom python dependency for model allowed: false\u001b[0m\n",
      "\u001b[34mEnable metrics API: true\u001b[0m\n",
      "\u001b[34mMetrics mode: log\u001b[0m\n",
      "\u001b[34mDisable system metrics: true\u001b[0m\n",
      "\u001b[34mWorkflow Store: /.sagemaker/ts/models\u001b[0m\n",
      "\u001b[34mModel config: N/A\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:03,884 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:03,907 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: /opt/ml/model\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:03,911 [WARN ] main org.pytorch.serve.archive.model.ModelArchive - Model archive version is not defined. Please upgrade to torch-model-archiver 0.2.0 or higher\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:03,912 [WARN ] main org.pytorch.serve.archive.model.ModelArchive - Model archive createdOn is not defined. Please upgrade to torch-model-archiver 0.2.0 or higher\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:03,915 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model model loaded.\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:03,931 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:04,184 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:04,185 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:04,195 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082\u001b[0m\n",
      "\u001b[34mModel server started.\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:06,540 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9002, pid=47\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:06,543 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:06,565 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:06,568 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - [PID]47\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:06,569 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:06,570 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:06,570 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9003, pid=49\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:06,576 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:06,579 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:06,588 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:06,589 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - [PID]49\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:06,589 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:06,589 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:06,591 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:06,610 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9002.\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:06,610 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9003.\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:06,618 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689967146618\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:06,619 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689967146619\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:06,690 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:06,697 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:06,738 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9001, pid=46\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:06,740 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:06,763 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:06,770 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - [PID]46\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:06,770 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:06,771 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:06,772 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:06,791 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9001.\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:06,792 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689967146792\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:06,856 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:07,152 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9000, pid=48\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:07,154 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:07,215 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:07,222 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - [PID]48\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:07,223 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:07,223 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:07,223 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:07,240 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:07,241 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689967147241\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:07,287 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:07,471 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 775\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:07,472 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3546.0|#WorkerName:W-9002-model_1.0,Level:Host|#hostname:3eb2280f5f71,timestamp:1689967147\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:07,473 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:79.0|#Level:Host|#hostname:3eb2280f5f71,timestamp:1689967147\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:07,532 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 818\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:07,533 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3607.0|#WorkerName:W-9003-model_1.0,Level:Host|#hostname:3eb2280f5f71,timestamp:1689967147\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:07,533 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:97.0|#Level:Host|#hostname:3eb2280f5f71,timestamp:1689967147\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:07,569 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 713\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:07,569 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3643.0|#WorkerName:W-9001-model_1.0,Level:Host|#hostname:3eb2280f5f71,timestamp:1689967147\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:07,570 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:65.0|#Level:Host|#hostname:3eb2280f5f71,timestamp:1689967147\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:07,774 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 475\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:07,774 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3850.0|#WorkerName:W-9000-model_1.0,Level:Host|#hostname:3eb2280f5f71,timestamp:1689967147\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:07,775 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:59.0|#Level:Host|#hostname:3eb2280f5f71,timestamp:1689967147\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:11,918 [INFO ] pool-2-thread-5 ACCESS_LOG - /169.254.255.130:45442 \"GET /ping HTTP/1.1\" 200 33\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:11,919 [INFO ] pool-2-thread-5 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:3eb2280f5f71,timestamp:1689967151\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:11,945 [INFO ] epollEventLoopGroup-3-2 ACCESS_LOG - /169.254.255.130:45444 \"GET /execution-parameters HTTP/1.1\" 404 2\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:11,947 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - Requests4XX.Count:1.0|#Level:Host|#hostname:3eb2280f5f71,timestamp:1689967151\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:12,039 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:3eb2280f5f71,timestamp:1689967152\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:12,041 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1689967152040\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:12,051 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1689967152\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:12,132 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Running batch transform job on 150 records.\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:12,133 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Batch transform job returned 150 records.\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:12,133 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:88.37|#ModelName:model,Level:Model|#hostname:3eb2280f5f71,1689967152,efbb65e4-94fd-41be-af67-93ef5b21ed57, pattern=[METRICS]\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:12,135 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:88.37|#ModelName:model,Level:Model|#hostname:3eb2280f5f71,requestID:efbb65e4-94fd-41be-af67-93ef5b21ed57,timestamp:1689967152\u001b[0m\n",
      "\u001b[35m2023-07-21T19:19:11,918 [INFO ] pool-2-thread-5 ACCESS_LOG - /169.254.255.130:45442 \"GET /ping HTTP/1.1\" 200 33\u001b[0m\n",
      "\u001b[35m2023-07-21T19:19:11,919 [INFO ] pool-2-thread-5 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:3eb2280f5f71,timestamp:1689967151\u001b[0m\n",
      "\u001b[35m2023-07-21T19:19:11,945 [INFO ] epollEventLoopGroup-3-2 ACCESS_LOG - /169.254.255.130:45444 \"GET /execution-parameters HTTP/1.1\" 404 2\u001b[0m\n",
      "\u001b[35m2023-07-21T19:19:11,947 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - Requests4XX.Count:1.0|#Level:Host|#hostname:3eb2280f5f71,timestamp:1689967151\u001b[0m\n",
      "\u001b[35m2023-07-21T19:19:12,039 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:3eb2280f5f71,timestamp:1689967152\u001b[0m\n",
      "\u001b[35m2023-07-21T19:19:12,041 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1689967152040\u001b[0m\n",
      "\u001b[35m2023-07-21T19:19:12,051 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1689967152\u001b[0m\n",
      "\u001b[35m2023-07-21T19:19:12,132 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Running batch transform job on 150 records.\u001b[0m\n",
      "\u001b[35m2023-07-21T19:19:12,133 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Batch transform job returned 150 records.\u001b[0m\n",
      "\u001b[35m2023-07-21T19:19:12,133 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:88.37|#ModelName:model,Level:Model|#hostname:3eb2280f5f71,1689967152,efbb65e4-94fd-41be-af67-93ef5b21ed57, pattern=[METRICS]\u001b[0m\n",
      "\u001b[35m2023-07-21T19:19:12,135 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:88.37|#ModelName:model,Level:Model|#hostname:3eb2280f5f71,requestID:efbb65e4-94fd-41be-af67-93ef5b21ed57,timestamp:1689967152\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:12,137 [INFO ] W-9002-model_1.0 ACCESS_LOG - /169.254.255.130:45452 \"POST /invocations HTTP/1.1\" 200 102\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:12,137 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:3eb2280f5f71,timestamp:1689967152\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:12,137 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:96036.597|#model_name:model,model_version:default|#hostname:3eb2280f5f71,timestamp:1689967152\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:12,138 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:193.517|#model_name:model,model_version:default|#hostname:3eb2280f5f71,timestamp:1689967152\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:12,139 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:3eb2280f5f71,timestamp:1689967152\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:12,141 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 93\u001b[0m\n",
      "\u001b[34m2023-07-21T19:19:12,141 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:8.0|#Level:Host|#hostname:3eb2280f5f71,timestamp:1689967152\u001b[0m\n",
      "\u001b[35m2023-07-21T19:19:12,137 [INFO ] W-9002-model_1.0 ACCESS_LOG - /169.254.255.130:45452 \"POST /invocations HTTP/1.1\" 200 102\u001b[0m\n",
      "\u001b[35m2023-07-21T19:19:12,137 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:3eb2280f5f71,timestamp:1689967152\u001b[0m\n",
      "\u001b[35m2023-07-21T19:19:12,137 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:96036.597|#model_name:model,model_version:default|#hostname:3eb2280f5f71,timestamp:1689967152\u001b[0m\n",
      "\u001b[35m2023-07-21T19:19:12,138 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:193.517|#model_name:model,model_version:default|#hostname:3eb2280f5f71,timestamp:1689967152\u001b[0m\n",
      "\u001b[35m2023-07-21T19:19:12,139 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:3eb2280f5f71,timestamp:1689967152\u001b[0m\n",
      "\u001b[35m2023-07-21T19:19:12,141 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 93\u001b[0m\n",
      "\u001b[35m2023-07-21T19:19:12,141 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:8.0|#Level:Host|#hostname:3eb2280f5f71,timestamp:1689967152\u001b[0m\n",
      "\u001b[32m2023-07-21T19:19:11.954:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformer.transform(\n",
    "    data=test_data,\n",
    "    content_type='text/csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-eu-west-1-661670223746/lstm-fcn-training-2023-07-21-19-11-29-799'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "0  1.0\n",
       "1  0.0\n",
       "2  2.0\n",
       "3  2.0\n",
       "4  2.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_predictions = sagemaker_session.read_s3_file(\n",
    "    bucket=bucket, \n",
    "    key_prefix=f\"{transformer.output_path.split('/')[-1]}/test_data.csv.out\"\n",
    ")\n",
    "\n",
    "batch_predictions = batch_predictions.split('\\n')[:-1]\n",
    "batch_predictions = pd.DataFrame(batch_predictions).astype(float)\n",
    "batch_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(batch_predictions.values == real_time_predictions.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_results = sagemaker_session.upload_string_as_file_body(\n",
    "    body=batch_predictions.to_csv(index=False, header=False),\n",
    "    bucket=bucket, \n",
    "    key=\"lstm-fcn-algo/data/inference/output/batch/batch_predictions.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Clean-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Delete the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting model with name: lstm-fcn-algo-2023-07-21-19-10-43-645-2023-07-21-19-11-29-048\n"
     ]
    }
   ],
   "source": [
    "transformer.delete_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Unsubscribe to the listing (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like to unsubscribe to the algorithm, follow these steps. Before you cancel the subscription, ensure that you do not have any [deployable model](https://console.aws.amazon.com/sagemaker/home#/models) created from the model package or using the algorithm. Note - You can find this information by looking at the container name associated with the model. \n",
    "\n",
    "**Steps to unsubscribe to product from AWS Marketplace**:\n",
    "1. Navigate to __Machine Learning__ tab on [__Your Software subscriptions page__](https://aws.amazon.com/marketplace/ai/library?productType=ml&ref_=mlmp_gitdemo_indust)\n",
    "2. Locate the listing that you want to cancel the subscription for, and then choose __Cancel Subscription__  to cancel the subscription.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
