{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "084a1fc3-eabe-49f0-bc01-3e31066b0d46",
   "metadata": {},
   "source": [
    "# LSTM-FCN SageMaker Algorithm Usage Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416c1c0a-b4f1-48f9-84f1-b8303df0b052",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a204effc-c756-4d97-b5d1-691d7ce52942",
   "metadata": {},
   "source": [
    "Load all necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39d5fae5-ad38-4d5b-938b-bf4b3b767bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ad4857-587c-4c1f-a873-c5ee5a7d9e96",
   "metadata": {},
   "source": [
    "Set up S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9909de72-b6d6-4e16-880e-882dbfd87a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6420c63-b960-4c1f-b395-54233c1362d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'lstm-fcn-bucket'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4fae37-fe11-4b8d-852c-b72abf19de2e",
   "metadata": {
    "tags": []
   },
   "source": [
    "Set up SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "796473f9-2711-4cd5-b2dd-b3be37d4f2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28471658-4428-4a17-986b-c4d73a2e0c7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sm_runtime = boto3.client('runtime.sagemaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0d13b03-e5a4-488d-b123-c80f101ef2a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sm_client = boto3.client('sagemaker')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a42382c-850c-4bde-8b96-1fd8d45b3391",
   "metadata": {},
   "source": [
    "Select the training and inference ECR images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a55eaf3-8dd1-4ede-8ae7-7484a1f3960a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_image = '661670223746.dkr.ecr.eu-west-1.amazonaws.com/lstm-fcn-training'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7be87b8a-4520-4cae-9a7b-63428ab8bcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_image = '661670223746.dkr.ecr.eu-west-1.amazonaws.com/lstm-fcn-inference'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2b5725-2f06-4da6-9367-61d3450b7712",
   "metadata": {},
   "source": [
    "Select the EC2 instance type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a56ba0b3-cc37-4f4b-90a1-a8b972f28703",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instance_type = 'ml.c4.xlarge'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8405da-b384-49b2-8e7a-56d4b9434849",
   "metadata": {},
   "source": [
    "Define the model name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fc4f52f-e361-4deb-8176-3a6af40540a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'sample-lstm-fcn-model'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80792ccb-fac2-4bd9-a8d1-aa74ff5c3498",
   "metadata": {},
   "source": [
    "Define the endpoint name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44008102-06da-4a56-ac7a-d12b1e9b9c25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint_name = 'sample-lstm-fcn-endpoint'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f0ef27-c5d9-44a0-a0ef-a81fce576848",
   "metadata": {},
   "source": [
    "Define the job names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "323086f9-4124-4409-bf77-97e948de0dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_job_name = 'sample-lstm-fcn-training'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77b2c0ab-2124-4a4b-8d2c-20e4b3a24ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_job_name = 'sample-lstm-fcn-tuning'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e7c7a32-e49e-4eba-aaa8-9aa31cc85ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_job_name = 'sample-lstm-fcn-inference'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ae4f95-42a6-4208-9341-3a0eefef3a4c",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccd73cc-677b-4e57-a977-a07c1ed9ad9d",
   "metadata": {},
   "source": [
    "Run a training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5612dfcf-bfaa-42e6-adf6-743a28592a32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "estimator = sagemaker.estimator.Estimator(\n",
    "    role=sm_role,\n",
    "    image_uri=training_image,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type=instance_type,\n",
    "    output_path=f's3://{bucket_name}/training/',\n",
    "    hyperparameters={\n",
    "        'units': 8,\n",
    "        'dropout': 0.8,\n",
    "        'filters-1': 4,\n",
    "        'filters-2': 4,\n",
    "        'filters-3': 4,\n",
    "        'kernel-size-1': 3,\n",
    "        'kernel-size-2': 3,\n",
    "        'kernel-size-3': 3,\n",
    "        'batch-size': 64,\n",
    "        'lr': 0.001,\n",
    "        'epochs': 10,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2582a051-a22e-4953-b58e-983d1505d92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: sample-lstm-fcn-training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-20 18:16:09 Starting - Starting the training job...\n",
      "2023-07-20 18:16:34 Starting - Preparing the instances for training......\n",
      "2023-07-20 18:17:25 Downloading - Downloading input data...\n",
      "2023-07-20 18:17:50 Training - Downloading the training image....................................\n",
      "2023-07-20 18:23:57 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2023-07-20 18:24:05,681 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2023-07-20 18:24:05,682 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-07-20 18:24:05,683 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-07-20 18:24:05,693 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2023-07-20 18:24:05,706 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2023-07-20 18:24:11,775 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-07-20 18:24:11,776 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-07-20 18:24:11,796 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-07-20 18:24:11,797 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-07-20 18:24:11,814 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-07-20 18:24:11,815 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-07-20 18:24:11,833 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"testing\": \"/opt/ml/input/data/testing\",\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.c4.xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch-size\": 64,\n",
      "        \"dropout\": 0.8,\n",
      "        \"epochs\": 10,\n",
      "        \"filters-1\": 4,\n",
      "        \"filters-2\": 4,\n",
      "        \"filters-3\": 4,\n",
      "        \"kernel-size-1\": 3,\n",
      "        \"kernel-size-2\": 3,\n",
      "        \"kernel-size-3\": 3,\n",
      "        \"lr\": 0.001,\n",
      "        \"units\": 8\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"testing\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.c4.xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": true,\n",
      "    \"job_name\": \"sample-lstm-fcn-training\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"/opt/ml/code\",\n",
      "    \"module_name\": \"training\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.c4.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.c4.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"training.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch-size\":64,\"dropout\":0.8,\"epochs\":10,\"filters-1\":4,\"filters-2\":4,\"filters-3\":4,\"kernel-size-1\":3,\"kernel-size-2\":3,\"kernel-size-3\":3,\"lr\":0.001,\"units\":8}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=training.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.c4.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c4.xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"testing\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"testing\",\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.c4.xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c4.xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=training\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=/opt/ml/code\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"testing\":\"/opt/ml/input/data/testing\",\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.c4.xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch-size\":64,\"dropout\":0.8,\"epochs\":10,\"filters-1\":4,\"filters-2\":4,\"filters-3\":4,\"kernel-size-1\":3,\"kernel-size-2\":3,\"kernel-size-3\":3,\"lr\":0.001,\"units\":8},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"testing\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c4.xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":true,\"job_name\":\"sample-lstm-fcn-training\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"training\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.c4.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c4.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"training.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch-size\",\"64\",\"--dropout\",\"0.8\",\"--epochs\",\"10\",\"--filters-1\",\"4\",\"--filters-2\",\"4\",\"--filters-3\",\"4\",\"--kernel-size-1\",\"3\",\"--kernel-size-2\",\"3\",\"--kernel-size-3\",\"3\",\"--lr\",\"0.001\",\"--units\",\"8\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TESTING=/opt/ml/input/data/testing\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH-SIZE=64\u001b[0m\n",
      "\u001b[34mSM_HP_DROPOUT=0.8\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=10\u001b[0m\n",
      "\u001b[34mSM_HP_FILTERS-1=4\u001b[0m\n",
      "\u001b[34mSM_HP_FILTERS-2=4\u001b[0m\n",
      "\u001b[34mSM_HP_FILTERS-3=4\u001b[0m\n",
      "\u001b[34mSM_HP_KERNEL-SIZE-1=3\u001b[0m\n",
      "\u001b[34mSM_HP_KERNEL-SIZE-2=3\u001b[0m\n",
      "\u001b[34mSM_HP_KERNEL-SIZE-3=3\u001b[0m\n",
      "\u001b[34mSM_HP_LR=0.001\u001b[0m\n",
      "\u001b[34mSM_HP_UNITS=8\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python310.zip:/opt/conda/lib/python3.10:/opt/conda/lib/python3.10/lib-dynload:/opt/conda/lib/python3.10/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.10 training.py --batch-size 64 --dropout 0.8 --epochs 10 --filters-1 4 --filters-2 4 --filters-3 4 --kernel-size-1 3 --kernel-size-2 3 --kernel-size-3 3 --lr 0.001 --units 8\u001b[0m\n",
      "\u001b[34m2023-07-20 18:24:11,938 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34m--------------------------------------\u001b[0m\n",
      "\u001b[34mTraining on 700 time series.\u001b[0m\n",
      "\u001b[34mTime series length: 100\u001b[0m\n",
      "\u001b[34mTime series labels: [0, 1, 2]\u001b[0m\n",
      "\u001b[34m--------------------------------------\u001b[0m\n",
      "\u001b[34m--------------------------------------\u001b[0m\n",
      "\u001b[34mTesting on 150 time series.\u001b[0m\n",
      "\u001b[34mTime series length: 100\u001b[0m\n",
      "\u001b[34mTime series labels: [0, 1, 2]\u001b[0m\n",
      "\u001b[34m--------------------------------------\u001b[0m\n",
      "\u001b[34m--------------------------------------\u001b[0m\n",
      "\u001b[34mTraining the model.\u001b[0m\n",
      "\u001b[34m--------------------------------------\u001b[0m\n",
      "\u001b[34mEpoch: 1, Training Loss: 0.0173, Training Accuracy: 0.3343, Test Loss: 0.0221, Test Accuracy: 0.3333\u001b[0m\n",
      "\u001b[34mEpoch: 2, Training Loss: 0.0171, Training Accuracy: 0.3371, Test Loss: 0.0219, Test Accuracy: 0.3400\u001b[0m\n",
      "\u001b[34mEpoch: 3, Training Loss: 0.0169, Training Accuracy: 0.3914, Test Loss: 0.0216, Test Accuracy: 0.3800\u001b[0m\n",
      "\u001b[34mEpoch: 4, Training Loss: 0.0167, Training Accuracy: 0.5914, Test Loss: 0.0213, Test Accuracy: 0.5333\u001b[0m\n",
      "\u001b[34mEpoch: 5, Training Loss: 0.0164, Training Accuracy: 0.7286, Test Loss: 0.0210, Test Accuracy: 0.7333\u001b[0m\n",
      "\u001b[34mEpoch: 6, Training Loss: 0.0161, Training Accuracy: 0.7543, Test Loss: 0.0207, Test Accuracy: 0.7400\u001b[0m\n",
      "\u001b[34mEpoch: 7, Training Loss: 0.0157, Training Accuracy: 0.8514, Test Loss: 0.0201, Test Accuracy: 0.8467\u001b[0m\n",
      "\u001b[34mEpoch: 8, Training Loss: 0.0153, Training Accuracy: 0.8571, Test Loss: 0.0196, Test Accuracy: 0.8733\u001b[0m\n",
      "\u001b[34mEpoch: 9, Training Loss: 0.0148, Training Accuracy: 0.8971, Test Loss: 0.0191, Test Accuracy: 0.8867\u001b[0m\n",
      "\u001b[34mEpoch: 10, Training Loss: 0.0143, Training Accuracy: 0.9071, Test Loss: 0.0185, Test Accuracy: 0.9067\u001b[0m\n",
      "\u001b[34m--------------------------------------\u001b[0m\n",
      "\u001b[34mScoring the model.\u001b[0m\n",
      "\u001b[34mtrain:loss 0.0143\u001b[0m\n",
      "\u001b[34mtrain:acc 0.9071\u001b[0m\n",
      "\u001b[34mtest:loss 0.0185\u001b[0m\n",
      "\u001b[34mtest:acc 0.9067\u001b[0m\n",
      "\u001b[34m--------------------------------------\u001b[0m\n",
      "\u001b[34m2023-07-20 18:24:17,228 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2023-07-20 18:24:17,228 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2023-07-20 18:24:17,229 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2023-07-20 18:24:34 Uploading - Uploading generated training model\n",
      "2023-07-20 18:24:34 Completed - Training job completed\n",
      "Training seconds: 428\n",
      "Billable seconds: 428\n"
     ]
    }
   ],
   "source": [
    "estimator.fit(\n",
    "    inputs={\n",
    "        'training': f's3://{bucket_name}/sample-data/train.csv',\n",
    "        'testing': f's3://{bucket_name}/sample-data/valid.csv'\n",
    "    },\n",
    "    job_name=training_job_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676bea48-f883-4aec-b277-63f752f72211",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6eddeb-9898-4d5c-b108-d8d99e832869",
   "metadata": {},
   "source": [
    "Run a tuning job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4ce13e1-a60d-49a3-b2cd-0030297c2fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.deprecations:train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "WARNING:sagemaker.deprecations:train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "estimator = sagemaker.estimator.Estimator(\n",
    "    role=sm_role,\n",
    "    image_uri=training_image,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type=instance_type,\n",
    "    output_path=f's3://{bucket_name}/tuning/',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06ffa22e-d74f-4186-ad94-a4faac637db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = sagemaker.tuner.HyperparameterTuner(\n",
    "    estimator, \n",
    "    objective_metric_name='test:acc', \n",
    "    metric_definitions=[\n",
    "        {\n",
    "          'Name': 'train:loss',\n",
    "          'Regex': 'train:loss ([0-9\\\\.]+)'\n",
    "        },\n",
    "        {\n",
    "          'Name': 'train:acc',\n",
    "          'Regex': 'train:acc ([0-9\\\\.]+)'\n",
    "        },\n",
    "        {\n",
    "          'Name': 'test:loss',\n",
    "          'Regex': 'test:loss ([0-9\\\\.]+)'\n",
    "        },\n",
    "        {\n",
    "          'Name': 'test:acc',\n",
    "          'Regex': 'test:acc ([0-9\\\\.]+)'\n",
    "        },\n",
    "    ],\n",
    "    hyperparameter_ranges={\n",
    "        'units': sagemaker.parameter.IntegerParameter(4, 16),\n",
    "        'dropout': sagemaker.parameter.ContinuousParameter(0.1, 0.9),\n",
    "        'filters-1': sagemaker.parameter.IntegerParameter(4, 16),\n",
    "        'filters-2': sagemaker.parameter.IntegerParameter(4, 16),\n",
    "        'filters-3': sagemaker.parameter.IntegerParameter(4, 16),\n",
    "        'kernel-size-1': sagemaker.parameter.IntegerParameter(3, 7),\n",
    "        'kernel-size-2': sagemaker.parameter.IntegerParameter(3, 7),\n",
    "        'kernel-size-3': sagemaker.parameter.IntegerParameter(3, 7),\n",
    "        'lr': sagemaker.parameter.ContinuousParameter(0.0001, 0.001),\n",
    "        'batch-size': sagemaker.parameter.CategoricalParameter([32, 64, 128]),\n",
    "        'epochs': sagemaker.parameter.IntegerParameter(5, 10),\n",
    "    },\n",
    "    strategy='Bayesian', \n",
    "    objective_type='Maximize', \n",
    "    max_jobs=5, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "688af3e0-c7bd-403b-bd8e-38fcca2df953",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: sample-lstm-fcn-tuning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".............................................................................................................................................!\n"
     ]
    }
   ],
   "source": [
    "tuner.fit(\n",
    "    inputs={\n",
    "        'training': f's3://{bucket_name}/sample-data/train.csv',\n",
    "        'testing': f's3://{bucket_name}/sample-data/valid.csv'\n",
    "    },\n",
    "    job_name=tuning_job_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60727d79-3c6a-427d-9ee2-88a6c8c9ec9d",
   "metadata": {},
   "source": [
    "Inspect the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5319f4b-8c18-40ff-a9c9-31b3e1ed0df0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch-size</th>\n",
       "      <th>dropout</th>\n",
       "      <th>epochs</th>\n",
       "      <th>filters-1</th>\n",
       "      <th>filters-2</th>\n",
       "      <th>filters-3</th>\n",
       "      <th>kernel-size-1</th>\n",
       "      <th>kernel-size-2</th>\n",
       "      <th>kernel-size-3</th>\n",
       "      <th>lr</th>\n",
       "      <th>units</th>\n",
       "      <th>TrainingJobName</th>\n",
       "      <th>TrainingJobStatus</th>\n",
       "      <th>FinalObjectiveValue</th>\n",
       "      <th>TrainingStartTime</th>\n",
       "      <th>TrainingEndTime</th>\n",
       "      <th>TrainingElapsedTimeSeconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64.0</td>\n",
       "      <td>0.501642</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>13.0</td>\n",
       "      <td>sample-lstm-fcn-tuning-005-dc09f9bd</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.8933</td>\n",
       "      <td>2023-07-20 18:36:18+00:00</td>\n",
       "      <td>2023-07-20 18:36:49+00:00</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.0</td>\n",
       "      <td>0.356617</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>8.0</td>\n",
       "      <td>sample-lstm-fcn-tuning-004-5c55aded</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.8267</td>\n",
       "      <td>2023-07-20 18:35:35+00:00</td>\n",
       "      <td>2023-07-20 18:36:06+00:00</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>128.0</td>\n",
       "      <td>0.417961</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>15.0</td>\n",
       "      <td>sample-lstm-fcn-tuning-003-9be5f289</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.3133</td>\n",
       "      <td>2023-07-20 18:34:23+00:00</td>\n",
       "      <td>2023-07-20 18:35:28+00:00</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>128.0</td>\n",
       "      <td>0.430234</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>7.0</td>\n",
       "      <td>sample-lstm-fcn-tuning-002-90f37842</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.5733</td>\n",
       "      <td>2023-07-20 18:33:41+00:00</td>\n",
       "      <td>2023-07-20 18:34:12+00:00</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.0</td>\n",
       "      <td>0.597184</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000911</td>\n",
       "      <td>5.0</td>\n",
       "      <td>sample-lstm-fcn-tuning-001-83a2d4e0</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.7800</td>\n",
       "      <td>2023-07-20 18:26:18+00:00</td>\n",
       "      <td>2023-07-20 18:33:17+00:00</td>\n",
       "      <td>419.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   batch-size   dropout  epochs  filters-1  filters-2  filters-3   \n",
       "0        64.0  0.501642     7.0       10.0        6.0        6.0  \\\n",
       "1        32.0  0.356617     7.0        7.0        4.0        5.0   \n",
       "2       128.0  0.417961     6.0       15.0       13.0        4.0   \n",
       "3       128.0  0.430234     7.0       12.0        9.0        9.0   \n",
       "4        32.0  0.597184     5.0       12.0        5.0       15.0   \n",
       "\n",
       "   kernel-size-1  kernel-size-2  kernel-size-3        lr  units   \n",
       "0            4.0            5.0            3.0  0.000466   13.0  \\\n",
       "1            7.0            4.0            7.0  0.000487    8.0   \n",
       "2            3.0            3.0            3.0  0.000129   15.0   \n",
       "3            4.0            7.0            4.0  0.000499    7.0   \n",
       "4            4.0            4.0            3.0  0.000911    5.0   \n",
       "\n",
       "                       TrainingJobName TrainingJobStatus  FinalObjectiveValue   \n",
       "0  sample-lstm-fcn-tuning-005-dc09f9bd         Completed               0.8933  \\\n",
       "1  sample-lstm-fcn-tuning-004-5c55aded         Completed               0.8267   \n",
       "2  sample-lstm-fcn-tuning-003-9be5f289         Completed               0.3133   \n",
       "3  sample-lstm-fcn-tuning-002-90f37842         Completed               0.5733   \n",
       "4  sample-lstm-fcn-tuning-001-83a2d4e0         Completed               0.7800   \n",
       "\n",
       "          TrainingStartTime           TrainingEndTime   \n",
       "0 2023-07-20 18:36:18+00:00 2023-07-20 18:36:49+00:00  \\\n",
       "1 2023-07-20 18:35:35+00:00 2023-07-20 18:36:06+00:00   \n",
       "2 2023-07-20 18:34:23+00:00 2023-07-20 18:35:28+00:00   \n",
       "3 2023-07-20 18:33:41+00:00 2023-07-20 18:34:12+00:00   \n",
       "4 2023-07-20 18:26:18+00:00 2023-07-20 18:33:17+00:00   \n",
       "\n",
       "   TrainingElapsedTimeSeconds  \n",
       "0                        31.0  \n",
       "1                        31.0  \n",
       "2                        65.0  \n",
       "3                        31.0  \n",
       "4                       419.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.analytics().dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3f06a0-4237-4601-8f48-da5799935aa4",
   "metadata": {},
   "source": [
    "## Batch Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff84accc-1ef8-43e0-9722-dd20dc36ee31",
   "metadata": {},
   "source": [
    "Run a batch transform job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc3a17d0-f365-42c8-ab18-cf70be1a8a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sagemaker.model.Model(\n",
    "    role=sm_role,\n",
    "    image_uri=inference_image,\n",
    "    model_data=f's3://{bucket_name}/training/{training_job_name}/output/model.tar.gz',\n",
    "    name=model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "174c00c0-330a-4a99-a2f1-282fb9f35ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: sample-lstm-fcn-model\n"
     ]
    }
   ],
   "source": [
    "transformer = model.transformer(\n",
    "    instance_count=1, \n",
    "    instance_type=instance_type,\n",
    "    accept='text/csv',\n",
    "    output_path=f's3://{bucket_name}/inference/{inference_job_name}/',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff6d1d6a-a6ed-43b7-8f0c-0693535b648d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating transform job with name: sample-lstm-fcn-inference\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...........................................................\u001b[34mWarning: TorchServe is using non-default JVM parameters: -XX:-UseContainerSupport\u001b[0m\n",
      "\u001b[34mWARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.\u001b[0m\n",
      "\u001b[34m2023-07-20T18:46:55,952 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...\u001b[0m\n",
      "\u001b[34m2023-07-20T18:46:56,060 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml\u001b[0m\n",
      "\u001b[34m2023-07-20T18:46:56,223 [INFO ] main org.pytorch.serve.ModelServer - \u001b[0m\n",
      "\u001b[34mTorchserve version: 0.8.0\u001b[0m\n",
      "\u001b[34mTS Home: /opt/conda/lib/python3.10/site-packages\u001b[0m\n",
      "\u001b[34mCurrent directory: /\u001b[0m\n",
      "\u001b[34mTemp directory: /home/model-server/tmp\u001b[0m\n",
      "\u001b[34mMetrics config path: /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml\u001b[0m\n",
      "\u001b[34mNumber of GPUs: 0\u001b[0m\n",
      "\u001b[34mNumber of CPUs: 4\u001b[0m\n",
      "\u001b[34mMax heap size: 1866 M\u001b[0m\n",
      "\u001b[34mPython executable: /opt/conda/bin/python3.10\u001b[0m\n",
      "\u001b[34mConfig file: /etc/sagemaker-ts.properties\u001b[0m\n",
      "\u001b[34mInference address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34mManagement address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34mMetrics address: http://127.0.0.1:8082\u001b[0m\n",
      "\u001b[34mModel Store: /.sagemaker/ts/models\u001b[0m\n",
      "\u001b[34mInitial Models: model=/opt/ml/model\u001b[0m\n",
      "\u001b[34mLog dir: /logs\u001b[0m\n",
      "\u001b[34mMetrics dir: /logs\u001b[0m\n",
      "\u001b[34mNetty threads: 0\u001b[0m\n",
      "\u001b[34mNetty client threads: 0\u001b[0m\n",
      "\u001b[34mDefault workers per model: 4\u001b[0m\n",
      "\u001b[34mBlacklist Regex: N/A\u001b[0m\n",
      "\u001b[34mMaximum Response Size: 6553500\u001b[0m\n",
      "\u001b[34mMaximum Request Size: 6553500\u001b[0m\n",
      "\u001b[34mLimit Maximum Image Pixels: true\u001b[0m\n",
      "\u001b[34mPrefer direct buffer: false\u001b[0m\n",
      "\u001b[34mAllowed Urls: [file://.*|http(s)?://.*]\u001b[0m\n",
      "\u001b[34mCustom python dependency for model allowed: false\u001b[0m\n",
      "\u001b[34mEnable metrics API: true\u001b[0m\n",
      "\u001b[34mMetrics mode: log\u001b[0m\n",
      "\u001b[34mDisable system metrics: true\u001b[0m\n",
      "\u001b[34mWorkflow Store: /.sagemaker/ts/models\u001b[0m\n",
      "\u001b[34mModel config: N/A\u001b[0m\n",
      "\u001b[34m2023-07-20T18:46:56,238 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...\u001b[0m\n",
      "\u001b[34m2023-07-20T18:46:56,272 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: /opt/ml/model\u001b[0m\n",
      "\u001b[34m2023-07-20T18:46:56,277 [WARN ] main org.pytorch.serve.archive.model.ModelArchive - Model archive version is not defined. Please upgrade to torch-model-archiver 0.2.0 or higher\u001b[0m\n",
      "\u001b[34m2023-07-20T18:46:56,277 [WARN ] main org.pytorch.serve.archive.model.ModelArchive - Model archive createdOn is not defined. Please upgrade to torch-model-archiver 0.2.0 or higher\u001b[0m\n",
      "\u001b[34m2023-07-20T18:46:56,282 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model model loaded.\u001b[0m\n",
      "\u001b[34m2023-07-20T18:46:56,300 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.\u001b[0m\n",
      "\u001b[34m2023-07-20T18:46:56,551 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34m2023-07-20T18:46:56,552 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.\u001b[0m\n",
      "\u001b[34m2023-07-20T18:46:56,575 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082\u001b[0m\n",
      "\u001b[34mModel server started.\u001b[0m\n",
      "\u001b[34m2023-07-20T18:46:59,279 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9002, pid=47\u001b[0m\n",
      "\u001b[34m2023-07-20T18:46:59,283 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[34m2023-07-20T18:46:59,298 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.\u001b[0m\n",
      "\u001b[34m2023-07-20T18:46:59,299 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - [PID]47\u001b[0m\n",
      "\u001b[34m2023-07-20T18:46:59,300 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[34m2023-07-20T18:46:59,300 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9\u001b[0m\n",
      "\u001b[34m2023-07-20T18:46:59,305 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[34m2023-07-20T18:46:59,334 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9002.\u001b[0m\n",
      "\u001b[34m2023-07-20T18:46:59,338 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689878819338\u001b[0m\n",
      "\u001b[34m2023-07-20T18:46:59,397 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[34m2023-07-20T18:46:59,428 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9000, pid=45\u001b[0m\n",
      "\u001b[34m2023-07-20T18:46:59,434 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[34m2023-07-20T18:46:59,469 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.\u001b[0m\n",
      "\u001b[34m2023-07-20T18:46:59,470 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - [PID]45\u001b[0m\n",
      "\u001b[34m2023-07-20T18:46:59,471 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[34m2023-07-20T18:46:59,471 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[34m2023-07-20T18:46:59,473 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9\u001b[0m\n",
      "\u001b[34m2023-07-20T18:46:59,486 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.\u001b[0m\n",
      "\u001b[34m2023-07-20T18:46:59,490 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689878819490\u001b[0m\n",
      "\u001b[34m2023-07-20T18:46:59,568 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[34m2023-07-20T18:46:59,785 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9003, pid=44\u001b[0m\n",
      "\u001b[34m2023-07-20T18:46:59,790 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[34m2023-07-20T18:46:59,821 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.\u001b[0m\n",
      "\u001b[34m2023-07-20T18:46:59,841 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - [PID]44\u001b[0m\n",
      "\u001b[34m2023-07-20T18:46:59,841 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[34m2023-07-20T18:46:59,841 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[34m2023-07-20T18:46:59,843 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9\u001b[0m\n",
      "\u001b[34m2023-07-20T18:46:59,849 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9003.\u001b[0m\n",
      "\u001b[34m2023-07-20T18:46:59,850 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689878819850\u001b[0m\n",
      "\u001b[34m2023-07-20T18:46:59,946 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[34m2023-07-20T18:47:00,127 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9001, pid=46\u001b[0m\n",
      "\u001b[34m2023-07-20T18:47:00,129 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[34m2023-07-20T18:47:00,153 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.\u001b[0m\n",
      "\u001b[34m2023-07-20T18:47:00,154 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - [PID]46\u001b[0m\n",
      "\u001b[34m2023-07-20T18:47:00,156 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[34m2023-07-20T18:47:00,156 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[34m2023-07-20T18:47:00,160 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9\u001b[0m\n",
      "\u001b[34m2023-07-20T18:47:00,162 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9001.\u001b[0m\n",
      "\u001b[34m2023-07-20T18:47:00,164 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1689878820164\u001b[0m\n",
      "\u001b[34m2023-07-20T18:47:00,231 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[34m2023-07-20T18:47:00,280 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 883\u001b[0m\n",
      "\u001b[34m2023-07-20T18:47:00,281 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:3985.0|#WorkerName:W-9002-model_1.0,Level:Host|#hostname:71e0c57446fb,timestamp:1689878820\u001b[0m\n",
      "\u001b[34m2023-07-20T18:47:00,281 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:60.0|#Level:Host|#hostname:71e0c57446fb,timestamp:1689878820\u001b[0m\n",
      "\u001b[34m2023-07-20T18:47:00,332 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 774\u001b[0m\n",
      "\u001b[34m2023-07-20T18:47:00,333 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:4041.0|#WorkerName:W-9000-model_1.0,Level:Host|#hostname:71e0c57446fb,timestamp:1689878820\u001b[0m\n",
      "\u001b[34m2023-07-20T18:47:00,333 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:69.0|#Level:Host|#hostname:71e0c57446fb,timestamp:1689878820\u001b[0m\n",
      "\u001b[34m2023-07-20T18:47:00,569 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 611\u001b[0m\n",
      "\u001b[34m2023-07-20T18:47:00,570 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:4275.0|#WorkerName:W-9003-model_1.0,Level:Host|#hostname:71e0c57446fb,timestamp:1689878820\u001b[0m\n",
      "\u001b[34m2023-07-20T18:47:00,572 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:111.0|#Level:Host|#hostname:71e0c57446fb,timestamp:1689878820\u001b[0m\n",
      "\u001b[34m2023-07-20T18:47:00,746 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 516\u001b[0m\n",
      "\u001b[34m2023-07-20T18:47:00,747 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:4451.0|#WorkerName:W-9001-model_1.0,Level:Host|#hostname:71e0c57446fb,timestamp:1689878820\u001b[0m\n",
      "\u001b[34m2023-07-20T18:47:00,747 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:67.0|#Level:Host|#hostname:71e0c57446fb,timestamp:1689878820\u001b[0m\n",
      "\n",
      "\u001b[34m2023-07-20T18:47:04,744 [INFO ] pool-2-thread-5 ACCESS_LOG - /169.254.255.130:56336 \"GET /ping HTTP/1.1\" 200 21\u001b[0m\n",
      "\u001b[34m2023-07-20T18:47:04,745 [INFO ] pool-2-thread-5 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:71e0c57446fb,timestamp:1689878824\u001b[0m\n",
      "\u001b[34m2023-07-20T18:47:04,788 [INFO ] epollEventLoopGroup-3-2 ACCESS_LOG - /169.254.255.130:56352 \"GET /execution-parameters HTTP/1.1\" 404 2\u001b[0m\n",
      "\u001b[34m2023-07-20T18:47:04,789 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - Requests4XX.Count:1.0|#Level:Host|#hostname:71e0c57446fb,timestamp:1689878824\u001b[0m\n",
      "\u001b[35m2023-07-20T18:47:04,744 [INFO ] pool-2-thread-5 ACCESS_LOG - /169.254.255.130:56336 \"GET /ping HTTP/1.1\" 200 21\u001b[0m\n",
      "\u001b[35m2023-07-20T18:47:04,745 [INFO ] pool-2-thread-5 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:71e0c57446fb,timestamp:1689878824\u001b[0m\n",
      "\u001b[35m2023-07-20T18:47:04,788 [INFO ] epollEventLoopGroup-3-2 ACCESS_LOG - /169.254.255.130:56352 \"GET /execution-parameters HTTP/1.1\" 404 2\u001b[0m\n",
      "\u001b[35m2023-07-20T18:47:04,789 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - Requests4XX.Count:1.0|#Level:Host|#hostname:71e0c57446fb,timestamp:1689878824\u001b[0m\n",
      "\u001b[34m2023-07-20T18:47:04,868 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:71e0c57446fb,timestamp:1689878824\u001b[0m\n",
      "\u001b[34m2023-07-20T18:47:04,869 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1689878824869\u001b[0m\n",
      "\u001b[34m2023-07-20T18:47:04,874 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1689878824\u001b[0m\n",
      "\u001b[34m2023-07-20T18:47:04,938 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Running batch transform job on 150 records.\u001b[0m\n",
      "\u001b[34m2023-07-20T18:47:04,939 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Batch transform job returned 150 records.\u001b[0m\n",
      "\u001b[34m2023-07-20T18:47:04,939 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:65.64|#ModelName:model,Level:Model|#hostname:71e0c57446fb,1689878824,65e411db-442d-44ac-99d6-244f1164bca5, pattern=[METRICS]\u001b[0m\n",
      "\u001b[34m2023-07-20T18:47:04,941 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:65.64|#ModelName:model,Level:Model|#hostname:71e0c57446fb,requestID:65e411db-442d-44ac-99d6-244f1164bca5,timestamp:1689878824\u001b[0m\n",
      "\u001b[34m2023-07-20T18:47:04,942 [INFO ] W-9002-model_1.0 ACCESS_LOG - /169.254.255.130:56354 \"POST /invocations HTTP/1.1\" 200 77\u001b[0m\n",
      "\u001b[34m2023-07-20T18:47:04,943 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:71e0c57446fb,timestamp:1689878824\u001b[0m\n",
      "\u001b[34m2023-07-20T18:47:04,943 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:72712.73|#model_name:model,model_version:default|#hostname:71e0c57446fb,timestamp:1689878824\u001b[0m\n",
      "\u001b[34m2023-07-20T18:47:04,944 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:227.724|#model_name:model,model_version:default|#hostname:71e0c57446fb,timestamp:1689878824\u001b[0m\n",
      "\u001b[34m2023-07-20T18:47:04,946 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:71e0c57446fb,timestamp:1689878824\u001b[0m\n",
      "\u001b[34m2023-07-20T18:47:04,946 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 70\u001b[0m\n",
      "\u001b[34m2023-07-20T18:47:04,947 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:8.0|#Level:Host|#hostname:71e0c57446fb,timestamp:1689878824\u001b[0m\n",
      "\u001b[35m2023-07-20T18:47:04,868 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:71e0c57446fb,timestamp:1689878824\u001b[0m\n",
      "\u001b[35m2023-07-20T18:47:04,869 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1689878824869\u001b[0m\n",
      "\u001b[35m2023-07-20T18:47:04,874 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1689878824\u001b[0m\n",
      "\u001b[35m2023-07-20T18:47:04,938 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Running batch transform job on 150 records.\u001b[0m\n",
      "\u001b[35m2023-07-20T18:47:04,939 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Batch transform job returned 150 records.\u001b[0m\n",
      "\u001b[35m2023-07-20T18:47:04,939 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:65.64|#ModelName:model,Level:Model|#hostname:71e0c57446fb,1689878824,65e411db-442d-44ac-99d6-244f1164bca5, pattern=[METRICS]\u001b[0m\n",
      "\u001b[35m2023-07-20T18:47:04,941 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:65.64|#ModelName:model,Level:Model|#hostname:71e0c57446fb,requestID:65e411db-442d-44ac-99d6-244f1164bca5,timestamp:1689878824\u001b[0m\n",
      "\u001b[35m2023-07-20T18:47:04,942 [INFO ] W-9002-model_1.0 ACCESS_LOG - /169.254.255.130:56354 \"POST /invocations HTTP/1.1\" 200 77\u001b[0m\n",
      "\u001b[35m2023-07-20T18:47:04,943 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:71e0c57446fb,timestamp:1689878824\u001b[0m\n",
      "\u001b[35m2023-07-20T18:47:04,943 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:72712.73|#model_name:model,model_version:default|#hostname:71e0c57446fb,timestamp:1689878824\u001b[0m\n",
      "\u001b[35m2023-07-20T18:47:04,944 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:227.724|#model_name:model,model_version:default|#hostname:71e0c57446fb,timestamp:1689878824\u001b[0m\n",
      "\u001b[35m2023-07-20T18:47:04,946 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:71e0c57446fb,timestamp:1689878824\u001b[0m\n",
      "\u001b[35m2023-07-20T18:47:04,946 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 70\u001b[0m\n",
      "\u001b[35m2023-07-20T18:47:04,947 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:8.0|#Level:Host|#hostname:71e0c57446fb,timestamp:1689878824\u001b[0m\n",
      "\u001b[32m2023-07-20T18:47:04.798:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "transformer.transform(\n",
    "    data=f's3://{bucket_name}/sample-data/test_data.csv',\n",
    "    content_type='text/csv',\n",
    "    job_name=inference_job_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd8b872-b304-4da8-9f4a-7590b02bb460",
   "metadata": {},
   "source": [
    "Inspect the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87b414ef-359d-4b72-9953-6282a13695fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 2 2 2 1 0 0 2 2 0 2 1 1 1 2 2 0 1 2 0 2 2 2 1 0 0 1 0 2 1 0 2 1 2 2 2\n",
      " 2 1 1 2 2 2 2 1 0 0 0 2 0 1 1 0 1 2 1 0 1 0 2 2 0 1 1 0 0 1 2 1 2 0 1 2 1\n",
      " 2 0 1 2 1 2 1 0 0 0 1 1 1 0 2 2 0 0 1 1 1 2 2 0 1 2 0 2 0 2 2 0 2 1 1 2 2\n",
      " 0 1 1 2 2 0 0 0 2 1 1 0 1 2 0 2 1 0 0 0 2 0 1 0 2 2 0 0 2 0 1 0 1 2 2 0 1\n",
      " 0 1]\n"
     ]
    }
   ],
   "source": [
    "body = s3_client.get_object(Bucket=bucket_name, Key=f'inference/{inference_job_name}/test_data.csv.out')['Body']\n",
    "data = body.read().decode('utf-8')\n",
    "df = pd.read_csv(io.StringIO(data), header=None, index_col=None)\n",
    "transformer_predictions = df.values.astype(int).flatten()\n",
    "print(transformer_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af387856-74ee-4d30-92dd-0e4e0545c8f5",
   "metadata": {},
   "source": [
    "## Real-Time Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef73823-2320-4121-812a-748ffa9d4eab",
   "metadata": {},
   "source": [
    "Deploy an endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b7a0a924-e993-4c03-ba0e-b8b1d6be5653",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: sample-lstm-fcn-model\n",
      "WARNING:sagemaker:Using already existing model: sample-lstm-fcn-model\n",
      "INFO:sagemaker:Creating endpoint-config with name sample-lstm-fcn-endpoint\n",
      "INFO:sagemaker:Creating endpoint with name sample-lstm-fcn-endpoint\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    serverless_inference_config=None,\n",
    "    endpoint_name=endpoint_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8c3a56-7fa6-4b52-a137-ad92b0cfc779",
   "metadata": {},
   "source": [
    "Invoke the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "869a9255-1b5b-4ea1-93e8-2f99ceb1de27",
   "metadata": {},
   "outputs": [],
   "source": [
    "body = s3_client.get_object(Bucket=bucket_name, Key=f'sample-data/test_data.csv')['Body']\n",
    "data = body.read().decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fa346325-adcb-417e-8e09-94eb558ec5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = sm_runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='text/csv',\n",
    "    Body=data\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a8442b-d17d-47ae-9c89-35d584458f0e",
   "metadata": {},
   "source": [
    "Inspect the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "06186652-ef6c-4e0c-82e0-7d7134a55739",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 2 2 2 1 0 0 2 2 0 2 1 1 1 2 2 0 1 2 0 2 2 2 1 0 0 1 0 2 1 0 2 1 2 2 2\n",
      " 2 1 1 2 2 2 2 1 0 0 0 2 0 1 1 0 1 2 1 0 1 0 2 2 0 1 1 0 0 1 2 1 2 0 1 2 1\n",
      " 2 0 1 2 1 2 1 0 0 0 1 1 1 0 2 2 0 0 1 1 1 2 2 0 1 2 0 2 0 2 2 0 2 1 1 2 2\n",
      " 0 1 1 2 2 0 0 0 2 1 1 0 1 2 0 2 1 0 0 0 2 0 1 0 2 2 0 0 2 0 1 0 1 2 2 0 1\n",
      " 0 1]\n"
     ]
    }
   ],
   "source": [
    "endpoint_predictions = np.array([int(x) for x in response['Body'].read().decode('utf-8').split('\\n')[:-1]], dtype=int)\n",
    "print(endpoint_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1ade77bb-c390-454f-8588-c402b1d56024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isclose(transformer_predictions, endpoint_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c186c38a-942a-4a3b-b644-1b46011d339d",
   "metadata": {},
   "source": [
    "Delete the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "80699433-819c-4a55-84fa-7d5736b4eadd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '205aabab-d4e3-4a1a-b0de-50a5a32d1659',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '205aabab-d4e3-4a1a-b0de-50a5a32d1659',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '0',\n",
       "   'date': 'Thu, 20 Jul 2023 18:54:29 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_client.delete_endpoint(EndpointName=endpoint_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
